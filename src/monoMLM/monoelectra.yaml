id: monoelectra
title: "monoELECTRA trained on MS-Marco"
description: |
    Inspired by

    Passage Re-ranking with BERT (Rodrigo Nogueira, Kyunghyun Cho). 2019.
    https://arxiv.org/abs/1901.04085

    This model has been trained on MsMarco v1, and uses the `google/electra-base-generator` checkpoint

gpu: true
file: experiment
base: google/electra-base-generator

preprocessing:
    requirements: duration=6h & cpu(mem=4G, cores=8)

indexation:
    requirements: duration=6h & cpu(mem=4G, cores=8)

validation:
    # Use 500 topics for validation
    size: 500

learner:
    optimization:
        steps_per_epoch: 64
        batch_size: 64
        max_epochs: 6_400
        num_warmup_steps: 10_000
        warmup_min_factor: 0
        weight_decay: 0.01
        lr: 3.0e-6
        eps: 1.0e-8

    validation_interval: 200
    requirements: duration=4 days & cpu(mem=10G) & cuda(mem=24G) * 2

retrieval:
    requirements: duration=12h & cpu(mem=10G) & cuda(mem=24G) * 2
    k: 1000
